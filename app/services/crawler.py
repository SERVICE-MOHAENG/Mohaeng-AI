import requests


class CityCrawler:
    """
    ë„ì‹œ ë°ì´í„° ìˆ˜ì§‘ê¸° (Wikipedia API ì „ìš©)
    """

    def __init__(self):
        self.wiki_api_url = "https://en.wikipedia.org/api/rest_v1/page/summary/"
        # [ìˆ˜ì •] ë´‡ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ í—¤ë” ì¶”ê°€ (í•„ìˆ˜)
        self.headers = {"User-Agent": "Mohaeng-AI-Bot/1.0 (Target: Education/Testing)"}

    def get_wikipedia_summary(self, city_name: str) -> str:
        try:
            # 1. URL ì¸ì½”ë”©
            formatted_name = city_name.strip().replace(" ", "_")
            url = f"{self.wiki_api_url}{formatted_name}"

            # 2. í—¤ë”ë¥¼ í¬í•¨í•˜ì—¬ ìš”ì²­ (ì¤‘ìš”!)
            response = requests.get(url, headers=self.headers, timeout=10)

            # 3. ìƒì„¸ ë””ë²„ê¹… ë¡œê·¸ (ì‹¤íŒ¨ ì›ì¸ íŒŒì•…ìš©)
            if response.status_code != 200:
                print(f"   âš ï¸ [API Fail] {city_name} -> Status: {response.status_code}")
                # 404: ë¬¸ì„œ ì—†ìŒ, 403: ì°¨ë‹¨ë¨
                return ""

            data = response.json()

            if data.get("type") == "disambiguation":
                print(f"   âš ï¸ [Skip] {city_name} -> ë™ìŒì´ì˜ì–´ ë¬¸ì„œì„")
                return ""

            return data.get("extract", "")

        except Exception as e:
            print(f"   ğŸ’¥ [Error] {city_name}: {e}")
            return ""
