import os
import sys

# í˜„ì¬ í´ë” ê²½ë¡œ ì¶”ê°€ (ëª¨ë“ˆ importìš©)
sys.path.append(os.getcwd())

from app.services.crawler import CityCrawler
from scripts.city_data import TARGET_CITIES


def test_crawler():
    print("ğŸ•µï¸ í¬ë¡¤ëŸ¬ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    crawler = CityCrawler()

    # í…ŒìŠ¤íŠ¸í•  ë„ì‹œ 3ê°œë§Œ ì„ ì • (ì„œìš¸, ë‰´ìš•, ì´ìƒí•œ ì´ë¦„ í…ŒìŠ¤íŠ¸ìš© ì œì£¼)
    # ì‹¤ì œ TARGET_CITIES ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¸ë±ìŠ¤ë¡œ ë½‘ê±°ë‚˜ ì§ì ‘ ì§€ì •
    test_targets = [
        TARGET_CITIES[0],  # ì„œìš¸ (Seoul)
        TARGET_CITIES[30],  # ë‰´ìš• (New York City)
        TARGET_CITIES[2],  # ì œì£¼ (Jeju City / Jeju) - ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° í…ŒìŠ¤íŠ¸
    ]

    for city_data in test_targets:
        korean_name = city_data["name"]

        # 1. ê²€ìƒ‰ì–´ ê²°ì • ë¡œì§ (ingest_data.pyì™€ ë™ì¼)
        from scripts.ingest_data import get_search_term

        search_term = get_search_term(korean_name)

        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì¤‘: {korean_name} (ê²€ìƒ‰ì–´: {search_term})")

        # 2. í¬ë¡¤ë§ ì‹¤í–‰
        try:
            result = crawler.get_city_info(search_term)

            print(f"   âœ… [Wiki] ë‚´ìš© ê¸¸ì´: {len(result['content'])}ì")
            print(f"   âœ… [Travel] ë‚´ìš© ê¸¸ì´: {len(result['travel_info'])}ì")

            # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            print(f"   ğŸ“„ ìœ„í‚¤ ë‚´ìš©: {result['content'][:50]}...")

        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    test_crawler()
